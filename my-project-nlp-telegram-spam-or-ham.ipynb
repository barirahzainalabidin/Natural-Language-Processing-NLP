{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7902951,"sourceType":"datasetVersion","datasetId":4641655}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-07T05:46:28.906107Z","iopub.execute_input":"2024-04-07T05:46:28.906427Z","iopub.status.idle":"2024-04-07T05:46:30.099279Z","shell.execute_reply.started":"2024-04-07T05:46:28.906398Z","shell.execute_reply":"2024-04-07T05:46:30.098395Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/telegram-spam-or-ham/dataset.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# A Word-Level Neural Language Model And Generate Text ","metadata":{}},{"cell_type":"code","source":"# load text\nfilename = '/kaggle/input/telegram-spam-or-ham/dataset.csv'\nfile = open(filename, 'rt')\ntext = file.read()\nfile.close()","metadata":{"execution":{"iopub.status.busy":"2024-04-07T05:46:30.100853Z","iopub.execute_input":"2024-04-07T05:46:30.101238Z","iopub.status.idle":"2024-04-07T05:46:30.251373Z","shell.execute_reply.started":"2024-04-07T05:46:30.101211Z","shell.execute_reply":"2024-04-07T05:46:30.250619Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\ndef load_doc_from_csv(file_path, column_name):\n    \"\"\"\n    Load document content from a CSV file.\n\n    Args:\n    - file_path (str): The path to the CSV file.\n    - column_name (str): The name of the column containing the document content.\n\n    Returns:\n    - str: Document content.\n    \"\"\"\n    try:\n        # Load CSV file\n        df = pd.read_csv(file_path)\n        # Extract document content from specified column\n        doc = df['text'].iloc[0]  # Assuming there's only one document in the CSV file\n        return doc\n    except FileNotFoundError:\n        print(\"File not found:\", file_path)\n        return None\n\n# Specify the file path and column name\nfile_path = '/kaggle/input/telegram-spam-or-ham/dataset.csv'  # Replace 'your_csv_file.csv' with the actual file path\ncolumn_name = 'text'  # Replace 'column_containing_document_content' with the actual column name\n\n# Load document\ndoc = load_doc_from_csv(file_path, column_name)\nif doc is not None:\n    print(doc[:200])  # Print the first 200 characters of the document","metadata":{"execution":{"iopub.status.busy":"2024-04-07T05:46:30.252556Z","iopub.execute_input":"2024-04-07T05:46:30.252842Z","iopub.status.idle":"2024-04-07T05:46:30.376379Z","shell.execute_reply.started":"2024-04-07T05:46:30.252819Z","shell.execute_reply":"2024-04-07T05:46:30.375500Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"naturally irresistible your corporate identity lt is really hard to recollect a company the market is full of suqgestions and the information isoverwhelminq but a good catchy logo stylish statlonery a\n","output_type":"stream"}]},{"cell_type":"code","source":"import string\n\n# turn a doc into clean tokens\ndef clean_doc(doc):\n    \"\"\"\n    Clean and tokenize a document.\n\n    Args:\n    - doc (str): The document to be cleaned.\n\n    Returns:\n    - list: List of clean tokens.\n    \"\"\"\n    # replace '--' with a space ' '\n    doc = doc.replace('--', ' ')\n    # split into tokens by white space\n    tokens = doc.split()\n    # remove punctuation and make lower case\n    table = str.maketrans('', '', string.punctuation)\n    tokens = [word.translate(table).lower() for word in tokens if word.isalpha()]\n    return tokens","metadata":{"execution":{"iopub.status.busy":"2024-04-07T05:46:30.379133Z","iopub.execute_input":"2024-04-07T05:46:30.379725Z","iopub.status.idle":"2024-04-07T05:46:30.385450Z","shell.execute_reply.started":"2024-04-07T05:46:30.379677Z","shell.execute_reply":"2024-04-07T05:46:30.384363Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Clean document\ntokens = clean_doc(doc)\n\n# Print the first 200 tokens\nprint(\"First 200 tokens:\")\nprint(tokens[:200])\n\n# Print total number of tokens and unique tokens\ntotal_tokens = len(tokens)\nunique_tokens = len(set(tokens))\nprint('Total Tokens:', total_tokens)\nprint('Unique Tokens:', unique_tokens)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T05:46:30.386528Z","iopub.execute_input":"2024-04-07T05:46:30.386850Z","iopub.status.idle":"2024-04-07T05:46:30.396589Z","shell.execute_reply.started":"2024-04-07T05:46:30.386825Z","shell.execute_reply":"2024-04-07T05:46:30.395772Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"First 200 tokens:\n['naturally', 'irresistible', 'your', 'corporate', 'identity', 'lt', 'is', 'really', 'hard', 'to', 'recollect', 'a', 'company', 'the', 'market', 'is', 'full', 'of', 'suqgestions', 'and', 'the', 'information', 'isoverwhelminq', 'but', 'a', 'good', 'catchy', 'logo', 'stylish', 'statlonery', 'and', 'outstanding', 'website', 'will', 'make', 'the', 'task', 'much', 'easier', 'we', 'do', 'not', 'promise', 'that', 'havinq', 'ordered', 'a', 'iogo', 'your', 'company', 'will', 'automaticaily', 'become', 'a', 'world', 'ieader', 'it', 'isguite', 'ciear', 'that', 'without', 'good', 'products', 'effective', 'business', 'organization', 'and', 'practicable', 'aim', 'it', 'will', 'be', 'hotat', 'nowadays', 'market', 'but', 'we', 'do', 'promise', 'that', 'your', 'marketing', 'efforts', 'will', 'become', 'much', 'more', 'effective', 'here', 'is', 'the', 'list', 'of', 'clear', 'benefits', 'creativeness', 'hand', 'made', 'original', 'logos', 'specially', 'done', 'to', 'reflect', 'your', 'distinctive', 'company', 'image', 'convenience', 'logo', 'and', 'stationery', 'are', 'provided', 'in', 'all', 'formats', 'easy', 'to', 'use', 'content']\nTotal Tokens: 121\nUnique Tokens: 86\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define the length of each sequence\nsequence_length = 50 + 1\n\n# Initialize a list to store sequences\nsequences = []\n\n# Generate sequences of tokens\nfor i in range(sequence_length, len(tokens)):\n    # Select sequence of tokens\n    sequence = tokens[i - sequence_length: i]\n    # Convert the sequence into a line\n    line = ' '.join(sequence)\n    # Store the line\n    sequences.append(line)\n\n# Print the total number of sequences\nprint('Total Sequences:', len(sequences))","metadata":{"execution":{"iopub.status.busy":"2024-04-07T05:46:30.397650Z","iopub.execute_input":"2024-04-07T05:46:30.397945Z","iopub.status.idle":"2024-04-07T05:46:30.407290Z","shell.execute_reply.started":"2024-04-07T05:46:30.397923Z","shell.execute_reply":"2024-04-07T05:46:30.406390Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Total Sequences: 70\n","output_type":"stream"}]},{"cell_type":"markdown","source":"> Train Language Model","metadata":{}},{"cell_type":"code","source":"!pip install --upgrade jax jaxlib\n","metadata":{"execution":{"iopub.status.busy":"2024-04-07T05:46:30.408506Z","iopub.execute_input":"2024-04-07T05:46:30.408787Z","iopub.status.idle":"2024-04-07T05:46:53.083731Z","shell.execute_reply.started":"2024-04-07T05:46:30.408761Z","shell.execute_reply":"2024-04-07T05:46:53.082780Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Requirement already satisfied: jax in /opt/conda/lib/python3.10/site-packages (0.4.23)\nCollecting jax\n  Downloading jax-0.4.26-py3-none-any.whl.metadata (23 kB)\nRequirement already satisfied: jaxlib in /opt/conda/lib/python3.10/site-packages (0.4.23.dev20240116)\nCollecting jaxlib\n  Downloading jaxlib-0.4.26-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.8 kB)\nRequirement already satisfied: ml-dtypes>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from jax) (0.2.0)\nRequirement already satisfied: numpy>=1.22 in /opt/conda/lib/python3.10/site-packages (from jax) (1.26.4)\nRequirement already satisfied: opt-einsum in /opt/conda/lib/python3.10/site-packages (from jax) (3.3.0)\nRequirement already satisfied: scipy>=1.9 in /opt/conda/lib/python3.10/site-packages (from jax) (1.11.4)\nDownloading jax-0.4.26-py3-none-any.whl (1.9 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading jaxlib-0.4.26-cp310-cp310-manylinux2014_x86_64.whl (78.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m78.8/78.8 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: jaxlib, jax\n  Attempting uninstall: jaxlib\n    Found existing installation: jaxlib 0.4.23.dev20240116\n    Uninstalling jaxlib-0.4.23.dev20240116:\n      Successfully uninstalled jaxlib-0.4.23.dev20240116\n  Attempting uninstall: jax\n    Found existing installation: jax 0.4.23\n    Uninstalling jax-0.4.23:\n      Successfully uninstalled jax-0.4.23\nSuccessfully installed jax-0.4.26 jaxlib-0.4.26\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom numpy import array\nfrom pickle import dump\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, LSTM, Embedding","metadata":{"execution":{"iopub.status.busy":"2024-04-07T05:46:53.085101Z","iopub.execute_input":"2024-04-07T05:46:53.085378Z","iopub.status.idle":"2024-04-07T05:47:05.908576Z","shell.execute_reply.started":"2024-04-07T05:46:53.085351Z","shell.execute_reply":"2024-04-07T05:47:05.907681Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"2024-04-07 05:46:55.217350: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-07 05:46:55.217445: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-07 05:46:55.381857: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load the dataset from CSV file\nfile_path = '/kaggle/input/telegram-spam-or-ham/dataset.csv'\ndf = pd.read_csv(file_path)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T05:47:05.909645Z","iopub.execute_input":"2024-04-07T05:47:05.910155Z","iopub.status.idle":"2024-04-07T05:47:06.022196Z","shell.execute_reply.started":"2024-04-07T05:47:05.910128Z","shell.execute_reply":"2024-04-07T05:47:06.021172Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Filter spam and ham messages\nspam_df = df[df['text_type'] == 'spam']\nham_df = df[df['text_type'] == 'ham']","metadata":{"execution":{"iopub.status.busy":"2024-04-07T05:47:06.025438Z","iopub.execute_input":"2024-04-07T05:47:06.025792Z","iopub.status.idle":"2024-04-07T05:47:06.907290Z","shell.execute_reply.started":"2024-04-07T05:47:06.025763Z","shell.execute_reply":"2024-04-07T05:47:06.906079Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Combine spam and ham messages\ndf = pd.concat([spam_df, ham_df])","metadata":{"execution":{"iopub.status.busy":"2024-04-07T05:47:06.908523Z","iopub.execute_input":"2024-04-07T05:47:06.908878Z","iopub.status.idle":"2024-04-07T05:47:06.915566Z","shell.execute_reply.started":"2024-04-07T05:47:06.908850Z","shell.execute_reply":"2024-04-07T05:47:06.914683Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Extract text and text type columns\nlines = df['text'].tolist()","metadata":{"execution":{"iopub.status.busy":"2024-04-07T05:47:06.916746Z","iopub.execute_input":"2024-04-07T05:47:06.917108Z","iopub.status.idle":"2024-04-07T05:47:06.925555Z","shell.execute_reply.started":"2024-04-07T05:47:06.917072Z","shell.execute_reply":"2024-04-07T05:47:06.924499Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Integer encode sequences of words\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(lines)\nsequences = tokenizer.texts_to_sequences(lines)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T05:47:06.926742Z","iopub.execute_input":"2024-04-07T05:47:06.927356Z","iopub.status.idle":"2024-04-07T05:47:09.000542Z","shell.execute_reply.started":"2024-04-07T05:47:06.927325Z","shell.execute_reply":"2024-04-07T05:47:08.999491Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Vocabulary size\nvocab_size = len(tokenizer.word_index) + 1","metadata":{"execution":{"iopub.status.busy":"2024-04-07T05:47:09.001875Z","iopub.execute_input":"2024-04-07T05:47:09.002246Z","iopub.status.idle":"2024-04-07T05:47:09.006776Z","shell.execute_reply.started":"2024-04-07T05:47:09.002215Z","shell.execute_reply":"2024-04-07T05:47:09.005824Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Pad sequences to ensure consistent length\nmax_sequence_length = max([len(seq) for seq in sequences])\nsequences = pad_sequences(sequences, maxlen=max_sequence_length, padding='pre')","metadata":{"execution":{"iopub.status.busy":"2024-04-07T05:47:09.007871Z","iopub.execute_input":"2024-04-07T05:47:09.008136Z","iopub.status.idle":"2024-04-07T05:47:09.213414Z","shell.execute_reply.started":"2024-04-07T05:47:09.008113Z","shell.execute_reply":"2024-04-07T05:47:09.212640Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, Flatten, Dense\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\n# Load the dataset from CSV file\nfile_path = '/kaggle/input/telegram-spam-or-ham/dataset.csv'\ndf = pd.read_csv(file_path)\n\n# Assuming 'data' is the DataFrame loaded from the CSV\nle = LabelEncoder()\ndf['target'] = le.fit_transform(df['text'])\n\n# Define problem\nvocab_size = 10000  # Assuming 'word_index' is predefined, otherwise adjust this value\nmax_length = 100\n\n# Convert text to sequences and pad sequences\ntokenizer = Tokenizer(num_words=vocab_size)\ntokenizer.fit_on_texts(df['text'])\nsequences = tokenizer.texts_to_sequences(df['text'])\npadded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')\n\n# Define the model\nmodel = Sequential()\nmodel.add(Embedding(input_dim=vocab_size, output_dim=8))  # Removed input_length parameter\nmodel.add(Flatten())\nmodel.add(Dense(units=1, activation='sigmoid'))\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# Train the model\nmodel.fit(padded_sequences, df['target'], epochs=10, batch_size=32, validation_split=0.2)\n\n# Summarize the model\nprint(model.summary())","metadata":{"execution":{"iopub.status.busy":"2024-04-07T05:47:09.214507Z","iopub.execute_input":"2024-04-07T05:47:09.214801Z","iopub.status.idle":"2024-04-07T05:47:25.470254Z","shell.execute_reply.started":"2024-04-07T05:47:09.214777Z","shell.execute_reply":"2024-04-07T05:47:25.469375Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m107/509\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0000e+00 - loss: -109044.0703","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1712468835.415304      95 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m509/509\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -8615766.0000 - val_accuracy: 9.8280e-04 - val_loss: -152776400.0000\nEpoch 2/10\n\u001b[1m509/509\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: -148941696.0000 - val_accuracy: 9.8280e-04 - val_loss: -614914368.0000\nEpoch 3/10\n\u001b[1m509/509\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: -461622528.0000 - val_accuracy: 9.8280e-04 - val_loss: -1333794048.0000\nEpoch 4/10\n\u001b[1m509/509\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: -926077120.0000 - val_accuracy: 9.8280e-04 - val_loss: -2270014720.0000\nEpoch 5/10\n\u001b[1m509/509\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: -1517213312.0000 - val_accuracy: 9.8280e-04 - val_loss: -3399120896.0000\nEpoch 6/10\n\u001b[1m509/509\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: -2236388864.0000 - val_accuracy: 9.8280e-04 - val_loss: -4702202368.0000\nEpoch 7/10\n\u001b[1m509/509\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: -2985311744.0000 - val_accuracy: 9.8280e-04 - val_loss: -6174325248.0000\nEpoch 8/10\n\u001b[1m509/509\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: -3900789760.0000 - val_accuracy: 9.8280e-04 - val_loss: -7799063040.0000\nEpoch 9/10\n\u001b[1m509/509\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: -4901786624.0000 - val_accuracy: 9.8280e-04 - val_loss: -9574303744.0000\nEpoch 10/10\n\u001b[1m509/509\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0000e+00 - loss: -6020096000.0000 - val_accuracy: 9.8280e-04 - val_loss: -11491467264.0000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\nâ”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\nâ”‚ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m8\u001b[0m)         â”‚        \u001b[38;5;34m80,000\u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ flatten (\u001b[38;5;33mFlatten\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              â”‚           \u001b[38;5;34m801\u001b[0m â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\nâ”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\nâ”‚ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">80,000</span> â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">801</span> â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m242,405\u001b[0m (946.90 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">242,405</span> (946.90 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m80,801\u001b[0m (315.63 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">80,801</span> (315.63 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m161,604\u001b[0m (631.27 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">161,604</span> (631.27 KB)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"None\n","output_type":"stream"}]},{"cell_type":"markdown","source":"> Use Language Model","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom random import randint\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Embedding, LSTM, Dense\n\n# Load cleaned text sequences from CSV file\ndf = pd.read_csv('/kaggle/input/telegram-spam-or-ham/dataset.csv')\nlines = df['text'].tolist()\n\n# Tokenize the text\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(lines)\nvocab_size = len(tokenizer.word_index) + 1\n\n# Generate sequences\nsequences = tokenizer.texts_to_sequences(lines)\nmax_length = max([len(seq) for seq in sequences])\nsequences = pad_sequences(sequences, maxlen=max_length, padding='pre')\n\n# Prepare input and output sequences\nX = sequences[:, :-1]\ny = sequences[:, -1]\n\n# Define the model\nmodel = Sequential()\nmodel.add(Embedding(vocab_size, 50))\nmodel.add(LSTM(100))\nmodel.add(Dense(vocab_size, activation='softmax'))\n\nmodel.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n# Fit the model\nmodel.fit(X, y, epochs=50, verbose=2)\n\n# Function to generate sequence\ndef generate_seq(model, tokenizer, seq_length, seed_text, n_words):\n    result = []\n    in_text = seed_text\n    for _ in range(n_words):\n        encoded = tokenizer.texts_to_sequences([in_text])[0]\n        encoded = pad_sequences([encoded], maxlen=seq_length, padding='pre')\n        # predict probabilities for each word\n        yhat = model.predict(encoded, verbose=0)\n        # map predicted word index to word\n        out_word = ''\n        for word, index in tokenizer.word_index.items():\n            if index == yhat.argmax():\n                out_word = word\n                break\n        in_text += ' ' + out_word\n        result.append(out_word)\n    return ' '.join(result)\n\n# Select a seed text\nseed_text = lines[randint(0, len(lines))]\nprint(seed_text + '\\n')\n\n# Generate new text\ngenerated = generate_seq(model, tokenizer, max_length-1, seed_text, 50)\nprint(generated)","metadata":{"execution":{"iopub.status.busy":"2024-04-07T05:58:58.787370Z","iopub.execute_input":"2024-04-07T05:58:58.787748Z","iopub.status.idle":"2024-04-07T06:19:18.566568Z","shell.execute_reply.started":"2024-04-07T05:58:58.787720Z","shell.execute_reply":"2024-04-07T06:19:18.565568Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Epoch 1/50\n636/636 - 27s - 42ms/step - accuracy: 0.0344 - loss: 9.1768\nEpoch 2/50\n636/636 - 23s - 36ms/step - accuracy: 0.0412 - loss: 7.8149\nEpoch 3/50\n636/636 - 23s - 36ms/step - accuracy: 0.0508 - loss: 7.2957\nEpoch 4/50\n636/636 - 23s - 36ms/step - accuracy: 0.0647 - loss: 6.8838\nEpoch 5/50\n636/636 - 23s - 36ms/step - accuracy: 0.0788 - loss: 6.5042\nEpoch 6/50\n636/636 - 23s - 36ms/step - accuracy: 0.0977 - loss: 6.1140\nEpoch 7/50\n636/636 - 23s - 36ms/step - accuracy: 0.1177 - loss: 5.7538\nEpoch 8/50\n636/636 - 23s - 36ms/step - accuracy: 0.1374 - loss: 5.4063\nEpoch 9/50\n636/636 - 23s - 36ms/step - accuracy: 0.1618 - loss: 5.0757\nEpoch 10/50\n636/636 - 23s - 36ms/step - accuracy: 0.1852 - loss: 4.7564\nEpoch 11/50\n636/636 - 23s - 36ms/step - accuracy: 0.2107 - loss: 4.4469\nEpoch 12/50\n636/636 - 23s - 36ms/step - accuracy: 0.2446 - loss: 4.1403\nEpoch 13/50\n636/636 - 23s - 36ms/step - accuracy: 0.2831 - loss: 3.8458\nEpoch 14/50\n636/636 - 41s - 65ms/step - accuracy: 0.3299 - loss: 3.5514\nEpoch 15/50\n636/636 - 23s - 36ms/step - accuracy: 0.3837 - loss: 3.2712\nEpoch 16/50\n636/636 - 23s - 36ms/step - accuracy: 0.4489 - loss: 2.9965\nEpoch 17/50\n636/636 - 23s - 36ms/step - accuracy: 0.5086 - loss: 2.7285\nEpoch 18/50\n636/636 - 23s - 36ms/step - accuracy: 0.5635 - loss: 2.4875\nEpoch 19/50\n636/636 - 23s - 36ms/step - accuracy: 0.6111 - loss: 2.2493\nEpoch 20/50\n636/636 - 41s - 65ms/step - accuracy: 0.6487 - loss: 2.0359\nEpoch 21/50\n636/636 - 23s - 36ms/step - accuracy: 0.6866 - loss: 1.8416\nEpoch 22/50\n636/636 - 23s - 36ms/step - accuracy: 0.7151 - loss: 1.6728\nEpoch 23/50\n636/636 - 23s - 36ms/step - accuracy: 0.7400 - loss: 1.5222\nEpoch 24/50\n636/636 - 23s - 36ms/step - accuracy: 0.7654 - loss: 1.3755\nEpoch 25/50\n636/636 - 23s - 36ms/step - accuracy: 0.7876 - loss: 1.2478\nEpoch 26/50\n636/636 - 23s - 36ms/step - accuracy: 0.8044 - loss: 1.1482\nEpoch 27/50\n636/636 - 23s - 36ms/step - accuracy: 0.8218 - loss: 1.0469\nEpoch 28/50\n636/636 - 23s - 36ms/step - accuracy: 0.8357 - loss: 0.9518\nEpoch 29/50\n636/636 - 23s - 36ms/step - accuracy: 0.8503 - loss: 0.8735\nEpoch 30/50\n636/636 - 23s - 36ms/step - accuracy: 0.8634 - loss: 0.8001\nEpoch 31/50\n636/636 - 23s - 36ms/step - accuracy: 0.8742 - loss: 0.7343\nEpoch 32/50\n636/636 - 23s - 36ms/step - accuracy: 0.8853 - loss: 0.6780\nEpoch 33/50\n636/636 - 23s - 36ms/step - accuracy: 0.8956 - loss: 0.6205\nEpoch 34/50\n636/636 - 23s - 36ms/step - accuracy: 0.9055 - loss: 0.5628\nEpoch 35/50\n636/636 - 23s - 36ms/step - accuracy: 0.9111 - loss: 0.5262\nEpoch 36/50\n636/636 - 23s - 36ms/step - accuracy: 0.9193 - loss: 0.4795\nEpoch 37/50\n636/636 - 23s - 36ms/step - accuracy: 0.9256 - loss: 0.4471\nEpoch 38/50\n636/636 - 23s - 36ms/step - accuracy: 0.9266 - loss: 0.4333\nEpoch 39/50\n636/636 - 23s - 36ms/step - accuracy: 0.9352 - loss: 0.3891\nEpoch 40/50\n636/636 - 23s - 36ms/step - accuracy: 0.9406 - loss: 0.3528\nEpoch 41/50\n636/636 - 23s - 36ms/step - accuracy: 0.9485 - loss: 0.3139\nEpoch 42/50\n636/636 - 23s - 36ms/step - accuracy: 0.9461 - loss: 0.3096\nEpoch 43/50\n636/636 - 23s - 36ms/step - accuracy: 0.9440 - loss: 0.3193\nEpoch 44/50\n636/636 - 23s - 36ms/step - accuracy: 0.9546 - loss: 0.2706\nEpoch 45/50\n636/636 - 23s - 36ms/step - accuracy: 0.9573 - loss: 0.2458\nEpoch 46/50\n636/636 - 41s - 65ms/step - accuracy: 0.9598 - loss: 0.2300\nEpoch 47/50\n636/636 - 23s - 36ms/step - accuracy: 0.9618 - loss: 0.2133\nEpoch 48/50\n636/636 - 23s - 36ms/step - accuracy: 0.9633 - loss: 0.2103\nEpoch 49/50\n636/636 - 23s - 36ms/step - accuracy: 0.9641 - loss: 0.2039\nEpoch 50/50\n636/636 - 23s - 36ms/step - accuracy: 0.9661 - loss: 0.1845\nwho do you want to be like? your role model: 1 sports person 2 actor 3 politician 1/ 2/ 3 send the name of your role model if the above does not apply\n\nglobalinvestment2 service 9584 service walks tc ğŸ‘‡ğŸ‘‡ğŸ‘‡ norm150ptone ğŸ‘‡ğŸ‘‡ğŸ‘‡ğŸ‘‡ğŸ‘‡ğŸ‘‡ğŸ‘‡ğŸ‘‡ğŸ‘‡ğŸ‘‡ globalinvestment2 ğŸ‘‡ğŸ‘‡ğŸ‘‡ğŸ‘‡ğŸ‘‡ğŸ‘‡ğŸ‘‡ğŸ‘‡ğŸ‘‡ğŸ‘‡ millerbtctrade skip here here ğŸ‘‡ ğŸ‘‡ ğŸ‘‡ ğŸ‘‡ ğŸ‘‡ ğŸ‘‡ ğŸ‘‡ ğŸ‘‡ ğŸ‘‡ ğŸ‘‡ ğŸ‘‡ ğŸ‘‡ ğŸ‘‡ ğŸ‘‡ ğŸ‘‡ ğŸ‘‡ ğŸ‘‡ ğŸ‘‡ ğŸ‘‡ ğŸ‘‡ ğŸ‘‡ ğŸ‘‡ ğŸ‘‡ ğŸ‘‡ ğŸ‘‡ ğŸ‘‡ ğŸ‘‡ ğŸ‘‡ ğŸ‘‡ asp asp picasso asp com asp\n","output_type":"stream"}]}]}